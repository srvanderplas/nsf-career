---
title: "Project Description"
bibliography: refs.bib
editor: 
  markdown: 
    wrap: sentence
---

::: {.content-visible when-format="pdf"}
\newsection{D}
:::

```{r new, echo=F, fig.width=2, fig.height=1.5,warning=F,message=F,out.width=".25\\textwidth", include = F}
nums<-rnorm(100,0,1)
df<-data.frame(s=1:100,nums)
library(ggplot2)
ggplot(df, aes(x=nums))+
  geom_histogram()+
  theme_classic(base_size=9)
```

<!-- https://vcresearch.berkeley.edu/sites/default/files/inline-files/CAREER_Writing_Guide_2017_final.pdf -->

# Overview

<!-- 1. Objectives/Specific Aims/Goals -->

<!-- Other names for these are goals, research thrusts, etc. You can call these whatever you like or whatever is most used in your field. -->

<!-- • Try to fit this information on one page. -->
<!-- • Start with a brief problem statement to introduce your research question and state why it is important. -->
<!-- • Put the solution to your research question in context of your overall, long-term career objectives. -->
<!-- • Identify the specific objective for the present proposal. -->
<!-- • Describe your overall hypothesis for your specific objective. -->
<!-- • List your specific aims for how you will accomplish the objectives of your proposal.  -->
<!--    o Each aim is to find out information, not to do a method (a method supports an aim, but is not the purpose of the aim; i.e., the aim should be outcome-oriented). -->
<!--    o Limit yourself to 2-4 aims. -->
<!--    o Be declarative (use short bullet points). -->
<!--    o Make sure aims are not inter-dependent but supportive of each other (i.e., make sure that if the first step of your proposal doesn’t turn out the way you expect, your entire proposal won't fail). -->
<!--    o Link your specific aims to hypotheses, as appropriate. -->
<!-- • Close this section with a statement on your expected outcomes, emphasizing the project's innovation. -->
<!-- • It can be very useful to try to diagram your objective and aims. -->
 

<!-- Overview and Objectives (Suggested length: 1-1.5 pages)  -->

 
<!-- Problem statement:  -->
<!-- Provide a succinct statement of the problem or opportunity your proposal will address.   -->
Statistical graphics and models are powerful tools to summarize data and support human decision making; however, empirical research on graphical perception is sparse relative to the number of decisions necessary to make a good chart. When relevant studies are available, they often use incomparable methods and produce conflicting results.
Chart design guidelines are often based on opinion, not empirical study, rendering many scientific communications sub-optimal or ineffective.
This is alarming: effective science communication is critical for cultivating public trust in the scientific process and ensuring that decision makers accurately interpret supporting information. 
<!-- State a long-term goal that includes both research and education.   -->
Addressing these challenges, my long-term career goal is to examine statistical graphics with the goal of *helping people use data more effectively*, and to apply this research to educate and inspire a new generation of scientists while supporting science literacy among the general public. 

<!-- Briefly address how your proposed research and education activities will help synthesize, build, and/or expand foundations in the relevant areas.  -->
This CAREER proposal addresses a fundamental research question underpinning this problem: *How do design decisions impact the use, design, and perception of data visualizations?* Three research objectives support this goal:

<!-- State the research objectives of the proposed work, along with any relevant hypotheses and rationales.  -->

-   **RO1:** Create a framework for comprehensive graphical testing across multiple levels of user engagement.
-   **RO2:** Assess the impact of measurement methods on experiments evaluating statistical graphics.
-   **RO3:** Empirically validate common chart design guidelines, measuring the impact of design decisions on task performance.

Integrated with these research efforts, the overall **education goal** is to leverage visualization research to motivate statistical learning and improve data-driven decision making in society. Three education objectives (EOs) address this goal:

<!-- State the education objectives of the proposed work, along with any relevant hypotheses and rationales.  -->

-   **EO1:** Develop and implement experiential learning activities in graphics for undergraduate introductory statistics courses.
-   **EO2:** Create graduate course modules for K-12 educators that connect ongoing research to engaging, hands-on classroom activities for teaching statistics, math, and science.
-   **EO3:** Improve the penetration of visualization research beyond academia by incorporating summaries of empirical studies in resources used by data scientists, industry analysts, and researchers in STEM disciplines.

<!-- Describe how the research and educational activities are integrated with one another or synergistic.   -->
Experiential learning activities will connect graphics research to critical concepts within statistics courses at the undergraduate level as well as in K-12 activities provided during graduate coursework for STEM educators. 
In addition, incorporating research summaries into general visualization resources will not only connect data visualization creators with research; improving these resources will improve teaching materials for statistical computing and will involve undergraduates in research and outreach in graphics and science communication. 

The research and educational activities described in this project have the potential to significantly improve how scientists communicate scientific results to each other as well as to the general public, increasing public trust in science and facilitating public decision making based on experimental data and results. 

# Intellectual Merit
<!-- Intellectual Merit (Suggested length: 1/4-1/2 page)  -->
<!-- Describe the potential of the project to advance knowledge within its own field or across different fields.  -->
This work will expand our understanding of graphical perception and communication by empirically and systematically examining chart design through comprehensive, task-based testing.
<!-- Describe the expected significance of your project with respect to the research plan.   -->
The proposed studies will be used to
generate a framework relating evaluation methods to user engagement with graphics,
establish the impact of different experimental design decisions on results, and 
promote integration of multiple evaluation methods
<!-- incorporating elements of quantitative and qualitative feedback  -->
to provide a holistic assessment of visualization effectiveness.
Additionally, this project will prioritize inclusion neurodiverse and disabled individuals, ensuring that design guidelines account for accessibility concerns.
<!-- beyond creation of alt-text for visual impairments or colorblind-friendly palette selection. -->
<!-- Explain the extent to which the proposed activities suggest and explore creative, original, or potentially transformative concepts.  -->
The results of the systematic examination of different experimental design and testing methods will not only ground design guidelines in empirical results; if successful, the experiments will also help reconcile the results from historical studies with conflicting results.
While there are task-based taxonomies for *selection of chart types*, a systematic framework for selecting *testing methods* based on levels of engagement and critical tasks is innovative; we expect that this framework will facilitate well-rounded experiments that examine chart design and use from multiple perspectives, providing nuanced results focused on audience use of graphics.
<!-- When possible, describe how your education plan will contribute to new knowledge (e.g., expected contributions to the field of STEM education).  -->
The education activities proposed in this project are closely tied to the research objectives, providing avenues for dissemination of research results as well as inclusion of audiences in graphics research. 
As a result, education and research activities will combine to support new pedagogical research in experiential learning. 
This new research will examine the use of statistical graphics as an entry-point to quantitative subjects for individuals who are not traditionally interested in pursuing STEM careers. 
<!-- Discuss your qualifications to lead the project.  -->
Previous collaborative research projects have established new and re-imagined old methods for testing statistical graphics; when combined with training and experience in statistics at the intersection of computer science, psychology, and communication, I am well equipped to complete this project supported by collaborations with researchers in cognitive psychology and statistical education. 


<!-- Relation to Principal Investigator’s Long-term Goals (Suggested length: 1/4-1/2 page)  -->
<!-- Restate the long-term goal of your research program and describe how the proposed work advances that long-term goal.  -->
My long-term career goal is to examine statistical graphics with the goal of *helping people use data more effectively*, and to apply this research to educate and inspire a new generation of scientists while supporting science literacy among the general public. 
<!-- Explain how the proposed project will build a firm foundation for a lifetime of leadership in research, education, and their integration.  -->

<!-- Explain how the proposed project will advance your career goals and job responsibilities as well as the mission of your department or organization.  -->

# Research Plan
<!-- Note: The research and educational activities do not need to be addressed separately if the relationship between them is such that it works best to present an integrated project where the two are interspersed throughout the Project Description. -->

## Background
<!-- (Suggested length: 2-4 pages)  -->
<!-- This section lets you: -->
<!-- 1. Orient reader to your subject, providing scientific background and context. -->
<!-- 2. Establish the importance and novelty of your project. -->
<!-- 3. Show your knowledge of the area through a solid review and objective citation of prior related work. -->
<!-- 4. Reveal that you are aware of opportunities, gaps, and roadblocks in your field.  -->
<!-- 5. Persuade the reviewers to become invested in your work by showing how your research matters for the field and their own research. -->
<!-- Write this section in nontechnical terms for a broader audience. -->

### Overview 

<!-- Briefly sketch the background leading to the present application, critically evaluate the existing literature, and identify gaps the project is intended to fill.   -->
Scientific graphics transform quantitative data into image representations that can make use of the human visual system, leveraging our ability to take in and process huge quantities of information with minimal cognitive effort.
However, unlike many mathematical data transformations, the transformation to visual space incurs loss both in the rendering of data to image and the transition from image to cognitive representation. 
That is, when creating data visualizations, we have to be concerned not only with the accuracy of the rendered image, but also with how that image is perceived by the viewer.
It is easy to find entire books filled with situations in which the transition from data to image produces results which are misleading [@cairoTruthfulArtData2016; @cairoHowChartsLie2019; @huffHowLieStatistics1954]; identifying scenarios where the transition from image to cognitive representation is suboptimal is more challenging and requires user studies. 
There have been empirical studies of graphics for at least 100 years [@croxtonBarChartsCircle1927; @eellsRelativeMeritsCircles1926; @wickham2013graphical], but the foundational work in graphical perception is @clevelandGraphicalPerceptionTheory1984, which established viewer's ability to accurately estimate information from simple visual displays. 
While this work is important, and valuable, it has been synthesized into recommendations and rankings which go far beyond the original experiments [@mackinlayAutomatingDesignGraphical1986; @franconeriScienceVisualData2021] with limited empirical verification, though in many cases these extrapolations are based in part on cognitive and perceptual research that is not specific to scientific visualization. 
In addition, it is easy to forget that @clevelandGraphicalPerceptionTheory1984 examined charts with respect to the direct numerical accuracy of quantitative estimates; the results do not necessarily apply if we are interested instead in determining whether differences between quantities can be perceived, ordered, or used to reach a reasonable real-world decision. 
While each of these alternate tasks has been addressed in user studies of graphics, it is extremely difficult to synthesize the total graphics literature across many different disciplines (including psychology, computer science, statistics, design, and communication) in order to derive empirically driven guidelines for creating graphs which not only accurately transform the data into an image but also present the data in a form which can be effectively used by the intended audience.

<!-- Discuss how this project will generate foundational research that will advance the field in general or address specific challenges of great importance.   -->
The research objectives proposed here are designed to lay a foundation for more consistent evaluation and testing of scientific visualizations. 
We focus on the level of user engagement with the chart: while there are hierarchies and taxonomies of graphical tasks that break down intended to help **designers** select the best graphical representation, we focus instead on how the ultimate target of the graph is intended to interact with the image and the information presented within.

We will first identify and evaluate methods for graphical testing across multiple levels of user engagement, comparing methods which test equivalent levels of engagement. 

<!-- Describe the contributions the project will make to synthesizing, expanding, or building the base of knowledge and evidence needed in the field and to the development of theory and methodology.  -->


### Review of Relevant Literature  

<!-- Provide a brief review of the pertinent literature to show the current state of the field and to illustrate the gap your proposed work will fill.  -->

<!-- Importance of Scientific visualizations -->
Statistical visualizations are a primary way scientists communicate results to other scientists as well as the general public, but we have been arguing about best practices for the visual display of data almost since these graphical forms were created [@wickham2013graphical; @croxtonBarChartsCircle1927; @eellsRelativeMeritsCircles1926].
Different individuals and organizations have released guidelines for graphical design [@JointCommitteeStandards1915; @brewerGuidelinesUsePerceptual1994; @kosslynGraphDesignEye2006; @tufteVisualDisplayQuantitative2001; @kelleherTenGuidelinesEffective2011], but many of these are based on aesthetic preferences, individual experience, or extrapolation from limited empirical studies; for an overview, see @kandogan_lee16.
Even when there are empirical studies to support guidelines for choosing one graphical form over another <!-- to increase perceptual accuracy and decrease viewer effort  --> [@cleveland1984; @hofmannGraphicalTestsPower2012; @spenceVisualPsychophysicsSimple1990; see @vanderplasTestingStatisticalCharts2020 for a review], these studies measure different quantities <!-- (estimation accuracy vs. ability to perceive a departure from a null model) --> in different ways <!-- (direct numerical estimation vs. comparative estimation of proportions) -->; the design and implementation differences have a potentially large effect on the generalizability of the results.
Complicating this problem, the design space of visualization user studies is incredibly large [@Abdul-Rahman2020], and studies can address charts from multiple perspectives, including perception, task-based interaction (with different tasks producing different results), structural characteristics, and more [@Bolte2020].
In addition, the test population is an important and under-examined aspect of the graphics experiment design space: we know that expertise as well as disorders such as dyslexia, dyscalculia, and ADHD affect perception, numeracy, and other processes involved in graph comprehension [@cheng_etal18; @chity_etal12; @hokken_etal23]; while these subpopulations can be difficult to test compared to the general population, empirical design recommendations must also address accessibility and audience considerations, as designers already consider these issues [@bako_etal23] but have no firm guidance about best practice.
<!-- Address Perception vs. Task vs. Structure vs. Meta Perception Testing methods (Measures in Visualization Space, Bolte & Bruckner, in Foundations of Data Visualization) --> 
Relatively few studies directly compare the effect of different approaches for testing graphics, but minor changes to data collection methods can impact accuracy of even simple numerical estimation tasks [@hondaNumberBiasWisdom2022]; it is reasonable to expect that the specifics of the graphical testing procedure used may impact the results, potentially explaining conflicting empirically based recommendations [@croxtonBarChartsCircle1927; @eellsRelativeMeritsCircles1926; @spenceVisualPsychophysicsSimple1990].
Without the ability to integrate results from different types of studies, it is hard to generate scientifically accurate recommendations from existing research.
To bridge this gap, information visualization needs a suite of easily implemented, validated graphical testing methods that are systematically applied to test existing design guidelines in order to produce nuanced, empirically grounded recommendations.

### Preliminary Studies 

<!-- Summarize any relevant preliminary supporting data.  -->
<!-- Can also be included in research plan -->
 
## Preliminary Data

<!-- b. Preliminary data -->

<!-- This is the place to highlight your own preliminary data, showing your ability to develop and test hypotheses, design rigorous experiments, perform experimental techniques, and analyze and interpret data. -->

<!-- • Illustrate the relevance of your preliminary data to your specific aims/goals and how it relates to your proposed research plan. -->

<!-- • Use high quality graphics and tables to illustrate your data and results. -->

During the early stages of the pandemic, log scales were fairly common because they allow comparison of different orders of magnitude on the same chart; however, it was difficult to find studies evaluating how successfully log scales were read and interpreted, though there were studies suggesting that people systematically under-predict exponential growth [@timmers_inverse_1977; @wagenaar_misperception_1975].
In order to address this gap in the literature, I worked with a graduate student, Emily Robinson, to design and execute a series of three studies addressing different tasks related to log scales: could participants detect a difference in rates of exponential growth?
Could they predict future values?
Could they estimate additive and multiplicative differences from an exponential time series?
We examined these questions by testing charts with log and linear scales using the lineup protocol [@buja_statistical_2009], participant drawn trends, and questions that required numerical calculation in a single omnibus study conducted using Prolific. Each set of results was analyzed separately [@robinson_human_2022, additional publications in progress], with additional publications discussing the implementation [@robinson_etal23] and validating the new method [@robinson_etal22] to gather data using participant-drawn trend lines. 
As expected when examining a single graphical choice using different methods, the results were mixed: using lineups, we determined that overall we have a hard time detecting changes in curvature, though we can detect a curve among straight lines more easily than we can detect a line (or less-steep curve) among curves. 
When assessing predictions, we found that the use of log scales reduced under-prediction of exponential growth. 
Finally, when examining participants' ability to estimate quantities from both types of charts, we found that participants tended to make serious inferential errors with regards to interpreting the language of the questions: questions asking for additive differences were often answered with multiplicative estimates, and vice versa, indicating that participants had trouble both with understanding the questions and visually estimating the answers.
Future work related to this study will analyze the differences in participant performance across methods to assess the importance of individual characteristics such as skill level and educational background. 
This COVID-era project has directly inspired the comparisons across different testing methods proposed here: we experimentally validated performance across a number of levels of engagement with similar data, varying the y-axis scale transformation. 
It would be extremely helpful to systematically examine the impact of experimental testing decisions, such as estimating the ratio (A/B) vs. the proportion (A/(A+B)), data collection methods (numeric estimation vs. slider with tick marks vs. slider without tick marks), and task-based testing methods: this would allow us to compare the impact of these decisions, selecting the most accurate testing method for the experimental question and providing some context that may allow us to reconcile the results of conflicting historical studies.

```{=html}
![Lineups (log and linear scale) test detection of differences in exponential growth rates.](log-lineups.png){#fig-lineups}
```

```{=tex}
\begin{wrapfigure}{R}{.5\textwidth}  
\includegraphics{log-lineups.png}
\caption{Lineups (log and linear scale) test detection of differences in exponential growth rates.}\label{fig-lineups}
\end{wrapfigure}
```

While there are many graph design and scientific communication questions which have not yet been experimentally tested, there is another problem with current literature: some comparisons were tested experimentally using graphics which were state-of-the-art at the time, but have not been re-examined in light of technological developments in the past 40-60 years. 
For instance, @cleveland1984 examined the use of fixed 3D projections of 2D data, but developments since the 1980s mean that analysts can now create 3D digital environments with appropriate shading and interactivity, and can even print these creations to create 3D charts that can be physically manipulated, touched, and considered from all angles. 
Are the guidelines that suggest 3D renderings are less accurately read and misleading still valid under these conditions?

![Three renderings of bar charts: 2D (left), 3D digital render (middle), and 3D printed (right).](images/3D-charts-sideways.png){#fig-3d-bar}

A graduate student and I have been investigating this question in two different populations: a population comparable to that used in @cleveland1984 (statistics faculty and graduate students and their roommates), and a population of introductory statistics students as part of an experiential learning project; the latter population is being tested in Summer 2023, but preliminary data is available from the former population. 
We have created charts rendered using 2D graphics, 3D digital renderings [@rglpkg], and 3D-printed graphics [@mariuskintelOpenSCADDocumentation2023], as shown in @fig-3d-bar. 
Our initial investigation found few differences between 2D, 3D digital, and 3D printed charts in comparison accuracy; as a result, we are expanding the study to determine whether this is a technological difference and the decreased accuracy in @cleveland1984 is a result of the 3D fixed-angle projection that does not allow for realistic manipulation. 
Misapplied depth perception has been implicated in other graphical mis-perceptions [@vanderplasSignsSineIllusion2015;@hofmannCommonAnglePlots2013], and it is entirely possible that 3D charts that are interactive can be accurately perceived while artificial 3D fixed-angle projections into 2D space lead to inaccurate perceptions. 
If this is the case, the guidelines to avoid 3D graphics may be entirely misguided given the rendering algorithms available today.

## Methods

[Link to Excel Sheet](https://uofnelincoln-my.sharepoint.com/:x:/g/personal/svanderplas2_unl_edu/EWdmaS7it8VMlxCsZ9_XRacB9zIwx2nIQZJoPzoeU3yD6Q?e=H9qwHb&nav=MTVfe0NDMjUzODdELUU4MDAtNDhGOS05OTg2LTZFRDA0NDI0NjFBOH0)

<!-- c. Methods -->
<!-- This is generally the longest section of the research plan, where you develop the details of your project. This section is not just about methods but design. -->
<!-- Suggested format for this section: -->
<!-- D. RESEARCH DESIGN AND METHODS -->
<!-- Introductory paragraph to orient reviewer to what you plan to do. -->
This project is designed to leverage human perception and statistics to facilitate better communication about data and statistical models, as shown in Figure 3. 



<!-- ```{=html} -->
<!-- ![Relationship between research aims.](images/cycle.png){#fig-cycle} -->
<!-- ``` -->

<!-- ```{=tex} -->
<!-- \begin{wrapfigure}{L}{.5\textwidth} -->
<!-- \includegraphics{images/cycle.pdf} -->
<!-- \caption{Relationship between research aims.}\label{fig-cycle} -->
<!-- \end{wrapfigure} -->
<!-- ``` -->


To address this broad goal, we will first benchmark methods for testing statistical graphics that correspond to typical uses for statistical graphics. 
We will then use these methods to assess design guidelines and recommendations, providing a more nuanced, task-focused, empirical evaluation of these design criteria to provide clarity in the importance and impact of design guidelines; if successful this will improve design criteria guidelines, but will also allow us to reconcile the results from conflicting historical experiments.
While these two goals are related, they are not dependent: there are already sufficient methods in the literature for testing graphics to allow us to complete a task-focused evaluation of design guidelines; our contribution in the first aim is to modernize historical methods, fill in gaps in task-focused analysis methods, provide direct comparisons between methods, and create guidelines for the use of each method when testing statistical graphics. 

<!-- When outlining your experimental plan: -->
<!-- • Base it on your specific aims—restate the aims and describe the flow of experiments for each aim. -->
<!-- • Describe methodology for each aim, establishing your expertise with the approach by linking back to your preliminary studies and assessing the strengths and limitations of your approach. -->
<!-- • Cite appropriate references. -->
<!-- • Describe the timeline and sequence of experiments. -->
<!-- • Talk about relevance to the field. -->

<!-- D.1. Aim 1. Repeat Specific Aim from page 1. -->
<!-- D.1.a. Hypothesis and Rationale. -->
<!-- D.1.b. Experimental Plan. -->
<!-- D.1.c. Expected Outcomes/Evaluation -->
<!-- D.1.d. Potential Pitfalls and Alternative Approaches -->
<!-- Discuss the limitations of each approach you are proposing and how they may affect your results and data.  -->
<!-- • Call attention to potential difficulties and propose alternatives you will use if a technique is inadequate or the results are inconclusive. -->
<!-- • Describe potential pitfalls and what you will do if they occur. -->
<!-- • State what you will do if results are negative, how negative findings will also advance the field, and what you will do next. -->
<!-- D.1.e Evaluation - Describe how you will assess your research program. -->
<!-- • Consider linking this to your timeline and/or milestones. -->
<!-- • Describe future plans. -->
<!-- • Identify what others will be able to do with your research results. -->
<!-- D.1.f Future Steps -->

<!-- D.2. Aim 2. Repeat Specific Aim from page 1. -->
<!-- D.2.a. Hypothesis and Rationale. -->
<!-- D.2.b. Experimental Plan. -->
<!-- D.2.c. Expected Outcomes/Evaluation -->
<!-- D.2.d. Potential Pitfalls and Alternative Approaches -->
<!-- Discuss the limitations of each approach you are proposing and how they may affect your results and data.  -->
<!-- • Call attention to potential difficulties and propose alternatives you will use if a technique is inadequate or the results are inconclusive. -->
<!-- • Describe potential pitfalls and what you will do if they occur. -->
<!-- • State what you will do if results are negative, how negative findings will also advance the field, and what you will do next. -->
<!-- D.2.e Evaluation - Describe how you will assess your research program. -->
<!-- • Consider linking this to your timeline and/or milestones. -->
<!-- • Describe future plans. -->
<!-- • Identify what others will be able to do with your research results. -->
<!-- D.2.f Future Steps -->

<!-- D.3. Aim 3. Repeat Specific Aim from page 1. -->
<!-- D.3.a. Hypothesis and Rationale. -->
<!-- D.3.b. Experimental Plan. -->
<!-- D.3.c. Expected Outcomes/Evaluation -->
<!-- D.3.d. Potential Pitfalls and Alternative Approaches -->
<!-- Discuss the limitations of each approach you are proposing and how they may affect your results and data.  -->
<!-- • Call attention to potential difficulties and propose alternatives you will use if a technique is inadequate or the results are inconclusive. -->
<!-- • Describe potential pitfalls and what you will do if they occur. -->
<!-- • State what you will do if results are negative, how negative findings will also advance the field, and what you will do next. -->
<!-- D.3.e Evaluation - Describe how you will assess your research program. -->
<!-- • Consider linking this to your timeline and/or milestones. -->
<!-- • Describe future plans. -->
<!-- • Identify what others will be able to do with your research results. -->
<!-- D.3.f Future Steps -->


# Education Plan
<!-- F. 		Education Plan (Suggested length: 3-4 pages)  -->
<!-- Tips: Use first person, and refer to experiences that have informed your approach to education/teaching/mentoring.  -->

<!-- Describe the educational activities that will be carried out to meet the education objectives set forth in Section A.   -->

<!-- Include clear statements of the education activities to be undertaken.  -->

<!-- Include any plans for collaboration with academia, industry, national laboratories, school and school districts, museums, etc.  -->

<!-- If international/global dimensions are included, clearly state how the education activities will be enhanced by the international engagements and describe the benefits to participants in the U.S. and abroad. Delineate how the activities fit within the context of the expertise, facilities, data, and other resources that are being applied globally in relevant areas of education, and how the CAREER award would position you and UNL to take a leadership role.  -->

<!-- Clearly state the intended impact of all education activities.   -->

<!-- Describe how you plan to evaluate the impact of the educational activities on students and other participants.  -->

<!-- When appropriate, draw on and cite research and best practices in curriculum, pedagogy, and evaluation.  -->

 
## Overview

<!-- a. Overview/background/aims -->
<!-- Frame a big picture for your education plan. Include background, motivation, rationale, and aims for each major activity in the plan (e.g., Aim 1, Aim 2, Aim 3.). Suggest limiting to 3 major aims. -->

## Design and methods

<!-- b. Design and methods -->
<!-- For each aim listed in 3a, describe the target audience, needs/gaps to be addressed, methods, resources (including  personnel, partnerships, budget), and measurable desired outcomes (i.e., what would success look like?). -->

## Evaluation

<!-- c. Evaluation -->
<!-- Describe how you will assess your education program. -->
<!-- • Consider linking this to your timeline. -->
<!-- Tip: Refer to the NSF User Friendly Handbook for Project Evaluation: nsf.gov/pubs/2002/nsf02057/nsf02057.pdf -->

## Integration of Research and Education
<!-- H.  	Integration of Research and Education (Suggested length: 1/4-1/2 page)  -->
<!-- How will your research impact your education goals and how will your education activities feed back into your research? -->
<!-- Briefly summarize how you will integrate research and education. Consider questions such as: How will you recruit and involve graduate and undergraduate students in research activities? What efforts will you make to recruit students from underrepresented minorities? How will you mentor students in your lab? What outreach activities will you organize, and are these activities aimed at or effective in reaching underrepresented demographics?  -->

# Timeline
<!-- G.  	Timeline (Suggested length: 1/4-1/2 page)  -->
<!-- Provide a timeline for the completion of both research and educational activities, along with key milestones.  -->

 
# Broader Impacts
<!-- I.	Broader Impacts (Suggested length: 1/4-1/2 page)  -->
<!-- Discuss the other broader impacts, besides the education activities, that will accrue from the project. Broader impacts may be accomplished through (1) the research itself, (2) activities directly related to the research, or (3) activities supported by, but complementary to, the project.  -->

 
# Results from Prior NSF Support
<!-- J.	Results from Prior NSF Support  -->
<!-- If the you (the PI) have received NSF support with an award end date in the past five years (including any current funding and no cost extensions), information on the award is required, regardless of whether the support was directly related to the proposal or not. In cases where you have received more than one award (excluding amendments to existing awards), you need only report on the one award that is most closely related to the proposal. Support means salary support, as well as any other funding awarded by NSF, including research, Graduate Research Fellowship, Major Research Instrumentation, conference, equipment, travel, and center awards, etc.  -->
<!-- The following information must be provided:  -->
<!-- The NSF award number, amount, and period of support.  -->
<!-- The title of the project.  -->
<!-- A summary of the results of the completed work, including accomplishments, supported by the award. The results must be separately described under two distinct headings: Intellectual Merit and Broader Impacts.  -->
<!-- A listing of the publications resulting from the NSF award (a complete bibliographic citation for each publication must be provided either in this section or in the References Cited section of the proposal); if none, state “No publications were produced under this award.”  -->
<!-- Evidence of research products and their availability, including, but not limited to: data, publications, samples, physical collections, software, and models, as described in any Data Management Plan.  -->
<!-- If the project was recently awarded and therefore no new results exist, describe the major goals and broader impacts of the project. Note that the proposal may contain up to five pages to describe the results.  Results may be summarized in fewer than five pages, which would give the balance of the 15 pages for the Project Description.  -->


::: {.content-visible when-format="pdf"}
\clearpage
:::

# References {.unnumbered}

::: {.content-visible when-format="pdf"}
\newsection{E}
:::
